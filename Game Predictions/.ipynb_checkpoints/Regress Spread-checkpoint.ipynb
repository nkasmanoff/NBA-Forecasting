{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the textbook, maximize the precision of these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILENAME = 'NBADATA.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#retain relevant columns. \n",
    "data = pd.read_csv(FILENAME) \n",
    "data['3P%'] = np.divide(data['3P'].values,data['3PA'].values) \n",
    "del data['3P'],data['3PA']\n",
    "data['FG%'] = np.divide(data['FG'].values,data['FGA'].values)\n",
    "del data['FG'],data['FGA']\n",
    "data['FT%'] = np.divide(data['FT'].values,data['FTA'].values)\n",
    "del data['Unnamed: 0'],data['PLUS_MINUS'],data['TOTAL']\n",
    "del data['FT'],data['FTA']\n",
    "del data['OU']\n",
    "#del data['Team']\n",
    "#data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teams = data.Team.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#iterate over those teams, make a rolling window over n games. \n",
    "N_GAMES = 5\n",
    "nba_data = pd.DataFrame([])\n",
    "for team in teams:\n",
    "    team_data = data.loc[data['Team'] == team]  #this contains the box score of every team game from 2013 to 2018. \n",
    "    stuff_to_turn_into_avgs = ['OR', 'DR', 'TOT', 'PF', 'ST', 'TO', 'BL', '3P%', 'FG%', 'FT%']\n",
    "    #if seasons are the same, do this here, use the GAME_ID signifier. \n",
    "    for col in team_data.columns:\n",
    "        if col in stuff_to_turn_into_avgs:\n",
    "            #split each season up here, \n",
    "            team_data['Rolling ' + col] = team_data[col].rolling(window=N_GAMES).mean().shift(1)\n",
    "            del team_data[col]\n",
    "                \n",
    "    nba_data =  nba_data.append(team_data)\n",
    "           # df = pd.concat([road_df,home_df],axis=1)\n",
    "#reorganize the dataset. \n",
    "nba_data_splits = nba_data.sort_values(by = ['GAME_ID', 'Home'], ascending=[True, True])\n",
    "nba_data_splits.dropna(inplace=True)  #null values come with rolling means, drop those now. \n",
    "\n",
    "#delete columns no longer of use, ie team name etc. Can consider keeping team name and see if helps chances. \n",
    "del nba_data_splits['GAME_ID'],nba_data_splits['Home'],nba_data_splits['Away'],nba_data_splits['Date']\n",
    "del nba_data_splits['Team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#now align the box scores so its one big one for each game, home team and road teams. \n",
    "\n",
    "road_df = nba_data_splits.iloc[::2]\n",
    "home_df = nba_data_splits.iloc[1::2]\n",
    "for col in nba_data_splits.columns:\n",
    "    road_df['road_' + col] = road_df[col]\n",
    "    home_df['home_' + col] = home_df[col]\n",
    "    \n",
    "    del road_df[col],home_df[col]\n",
    "\n",
    "home_df.reset_index(inplace=True)\n",
    "road_df.reset_index(inplace=True)\n",
    "\n",
    "#merged into a dataframe here. \n",
    "df = pd.concat([road_df,home_df],axis=1)\n",
    "del df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataset here. Can consider the spread, or winner. \n",
    "#at the moment only using a single classifier, that seems sufficient. A home team loss is synonymous with a road team win. \n",
    "spread = True\n",
    "winner = False\n",
    "\n",
    "df['final_SPREAD'] = df['road_PTS'] - df['home_PTS']\n",
    "del df['road_PTS'], df['home_PTS'],df['home_SPREAD']\n",
    "           # if openspread + endspread <0:\n",
    "            #    y.append(np.array([0,1,0]))  #home team covered\n",
    "            #elif openspread + endspread >0:\n",
    "            #    y.append(np.array([1,0,0]))  #road covered\n",
    "           # else: \n",
    "           #     y.append(np.array([0,0,1]))  #push!\n",
    "y = []\n",
    "\n",
    "if spread: \n",
    "    for i in range(len(df)):\n",
    "        if df['road_SPREAD'].values[i] + df['final_SPREAD'].values[i] < 0:\n",
    "            y.append(1) #home team covers\n",
    "        else: # df['road_SPREAD'].values[i] + df['final_SPREAD'].values[i] > 0:\n",
    "            y.append(0) #road team covers or push\n",
    "    #else:\n",
    "    #    y.append(np.array([0,1]))  #push! \n",
    "    \n",
    "if winner:\n",
    "    for i in range(len(df)):\n",
    "        if df['final_SPREAD'].values[i] < 0: #home team won. \n",
    "            y.append([0,1])\n",
    "        else:\n",
    "            y.append([1,0]) #road team won. \n",
    "\n",
    "del df['final_SPREAD']\n",
    "\n",
    "y_names = np.array(['road team win', 'home team win']) #for preprocessing/visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scale and split the data here. \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#this is done in a relatively un-pythonic way. Can also all be in one line! \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(df.values)\n",
    "y=np.array(y)\n",
    "X = scaler.transform(df.values)\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y,random_state = 69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying some simple stuff right here. Want to use polynomial ordering, besides that go back to the copy 1 version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534639175258\n",
      "0.498453927025\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "print(logreg.score(X_train,y_train))\n",
    "\n",
    "print(logreg.score(X_test,y_test))  #bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "poly_transformer = PolynomialFeatures(degree=2,interaction_only=True,include_bias=False)\n",
    "X_train_poly = poly_transformer.fit_transform(X_train)\n",
    "\n",
    "X_test_poly = poly_transformer.fit_transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "principal_features = 3\n",
    "pca = PCA(n_components = principal_features)\n",
    "\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)  #turns it into a two feature dataset. \n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n",
      "0.534639175258\n",
      "0.498453927025\n",
      "\n",
      "Poly\n",
      "0.567835051546\n",
      "0.510822510823\n",
      "\n",
      "PCA\n",
      "0.521649484536\n",
      "0.510822510823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "print(\"Normal\")\n",
    "logreg.fit(X_train,y_train)\n",
    "print(logreg.score(X_train,y_train))\n",
    "\n",
    "print(logreg.score(X_test,y_test))\n",
    "print(\"\")\n",
    "print(\"Poly\")\n",
    "logreg.fit(X_train_poly,y_train)\n",
    "print(logreg.score(X_train_poly,y_train))\n",
    "\n",
    "print(logreg.score(X_test_poly,y_test))\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"PCA\")\n",
    "logreg.fit(X_train_pca,y_train)\n",
    "print(logreg.score(X_train_pca,y_train))\n",
    "\n",
    "print(logreg.score(X_test_pca,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "0.528659793814\n",
      "0.515769944341\n",
      "precision=  0.511235955056\n",
      "\n",
      "poly\n",
      "0.549690721649\n",
      "0.489177489177\n",
      "precision=  0.472650771388\n",
      "\n",
      "pca\n",
      "0.520824742268\n",
      "0.514533085962\n",
      "precision=  0.504545454545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier()\n",
    "\n",
    "print(\"normal\")\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test,y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n",
    "\n",
    "print()\n",
    "print(\"poly\")\n",
    "model.fit(X_train_poly,y_train)\n",
    "print(model.score(X_train_poly,y_train))\n",
    "print(model.score(X_test_poly,y_test))\n",
    "y_pred = model.predict(X_test_poly)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n",
    "\n",
    "print()\n",
    "print(\"pca\")\n",
    "\n",
    "model.fit(X_train_pca,y_train)\n",
    "print(model.score(X_train_pca,y_train))\n",
    "print(model.score(X_test_pca,y_test))\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print('precision= ',precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "0.98412371134\n",
      "0.52257266543\n",
      "precision=  0.513368983957\n",
      "\n",
      "poly\n",
      "0.98412371134\n",
      "0.510204081633\n",
      "precision=  0.495667244367\n",
      "\n",
      "pca\n",
      "0.98\n",
      "0.488559059988\n",
      "precision=  0.464157706093\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "print(\"normal\")\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test,y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n",
    "\n",
    "print()\n",
    "print(\"poly\")\n",
    "model.fit(X_train_poly,y_train)\n",
    "print(model.score(X_train_poly,y_train))\n",
    "print(model.score(X_test_poly,y_test))\n",
    "y_pred = model.predict(X_test_poly)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n",
    "\n",
    "print()\n",
    "print(\"pca\")\n",
    "\n",
    "model.fit(X_train_pca,y_train)\n",
    "print(model.score(X_train_pca,y_train))\n",
    "print(model.score(X_test_pca,y_test))\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print('precision= ',precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "0.70618556701\n",
      "0.498453927025\n",
      "precision=  0.478873239437\n",
      "\n",
      "poly\n",
      "0.781030927835\n",
      "0.482993197279\n",
      "precision=  0.457831325301\n",
      "\n",
      "pca\n",
      "0.628453608247\n",
      "0.519480519481\n",
      "precision=  0.511574074074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "print(\"normal\")\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test,y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n",
    "\n",
    "print()\n",
    "print(\"poly\")\n",
    "model.fit(X_train_poly,y_train)\n",
    "print(model.score(X_train_poly,y_train))\n",
    "print(model.score(X_test_poly,y_test))\n",
    "y_pred = model.predict(X_test_poly)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n",
    "\n",
    "print()\n",
    "print(\"pca\")\n",
    "\n",
    "model.fit(X_train_pca,y_train)\n",
    "print(model.score(X_train_pca,y_train))\n",
    "print(model.score(X_test_pca,y_test))\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print('precision= ',precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "0.684948453608\n",
      "0.505875077304\n",
      "precision=  0.492346938776\n",
      "\n",
      "poly\n",
      "0.691340206186\n",
      "0.508348794063\n",
      "precision=  0.494845360825\n",
      "\n",
      "pca\n",
      "0.689072164948\n",
      "0.47680890538\n",
      "precision=  0.459422283356\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "print(\"normal\")\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test,y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n",
    "\n",
    "print()\n",
    "print(\"poly\")\n",
    "model.fit(X_train_poly,y_train)\n",
    "print(model.score(X_train_poly,y_train))\n",
    "print(model.score(X_test_poly,y_test))\n",
    "y_pred = model.predict(X_test_poly)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n",
    "\n",
    "print()\n",
    "print(\"pca\")\n",
    "\n",
    "model.fit(X_train_pca,y_train)\n",
    "print(model.score(X_train_pca,y_train))\n",
    "print(model.score(X_test_pca,y_test))\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "0.519175257732\n",
      "0.513296227582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=  0.0\n",
      "\n",
      "poly\n",
      "0.519175257732\n",
      "0.513296227582\n",
      "precision=  0.0\n",
      "\n",
      "pca\n",
      "0.519175257732\n",
      "0.513296227582\n",
      "precision=  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "\n",
    "print(\"normal\")\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test,y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n",
    "\n",
    "print()\n",
    "print(\"poly\")\n",
    "model.fit(X_train_poly,y_train)\n",
    "print(model.score(X_train_poly,y_train))\n",
    "print(model.score(X_test_poly,y_test))\n",
    "y_pred = model.predict(X_test_poly)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n",
    "\n",
    "print()\n",
    "print(\"pca\")\n",
    "\n",
    "model.fit(X_train_pca,y_train)\n",
    "print(model.score(X_train_pca,y_train))\n",
    "print(model.score(X_test_pca,y_test))\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "0.546804123711\n",
      "0.493506493506\n",
      "precision=  0.473244147157\n",
      "\n",
      "poly\n",
      "0.541030927835\n",
      "0.492269635127\n",
      "precision=  0.475362318841\n",
      "\n",
      "pca\n",
      "0.525567010309\n",
      "0.517006802721\n",
      "precision=  0.510344827586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "\n",
    "print(\"normal\")\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test,y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n",
    "\n",
    "print()\n",
    "print(\"poly\")\n",
    "model.fit(X_train_poly,y_train)\n",
    "print(model.score(X_train_poly,y_train))\n",
    "print(model.score(X_test_poly,y_test))\n",
    "y_pred = model.predict(X_test_poly)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n",
    "\n",
    "print()\n",
    "print(\"pca\")\n",
    "\n",
    "model.fit(X_train_pca,y_train)\n",
    "print(model.score(X_train_pca,y_train))\n",
    "print(model.score(X_test_pca,y_test))\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "1.0\n",
      "0.486703772418\n",
      "precision=  0.470507544582\n",
      "\n",
      "poly\n",
      "1.0\n",
      "0.52257266543\n",
      "precision=  0.509752925878\n",
      "\n",
      "pca\n",
      "1.0\n",
      "0.492269635127\n",
      "precision=  0.47875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "print(\"normal\")\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test,y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n",
    "\n",
    "print()\n",
    "print(\"poly\")\n",
    "model.fit(X_train_poly,y_train)\n",
    "print(model.score(X_train_poly,y_train))\n",
    "print(model.score(X_test_poly,y_test))\n",
    "y_pred = model.predict(X_test_poly)\n",
    "print('precision= ',precision_score(y_test,y_pred))\n",
    "\n",
    "print()\n",
    "print(\"pca\")\n",
    "\n",
    "model.fit(X_train_pca,y_train)\n",
    "print(model.score(X_train_pca,y_train))\n",
    "print(model.score(X_test_pca,y_test))\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print('precision= ',precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print('precision= ',precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier()\n",
    "\n",
    "model.fit(X_trainval,y_trainval)\n",
    "model.n_layers_ = 4\n",
    "print(model.n_layers_)\n",
    "model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainval,X_test,y_trainval,y_test = train_test_split(X,y,random_state = 0)\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_trainval,y_trainval,random_state = 1)\n",
    "#print size of datasets here\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [.001,.01,.1,1,10,100]:\n",
    "    for C in [.001,.01,.1,1,10,100]:\n",
    "        svm = SVC(gamma=gamma,C=C)\n",
    "        svm.fit(X_train,y_train)\n",
    "        score = svm.score(X_val,y_val)\n",
    "        if score > best_score:\n",
    "            print(\"obtained score:\", score)\n",
    "\n",
    "            best_score = score\n",
    "            best_parameters = {'C' : C,'gamma' : gamma}\n",
    "\n",
    "svm = SVC(gamma=best_parameters['gamma'],C=best_parameters['C'])\n",
    "svm.fit(X_trainval,y_trainval)\n",
    "test_score = svm.score(X_test,y_test)\n",
    "print(\"best params: \",best_parameters['gamma'],best_parameters['C'])\n",
    "print(\"test score w/ best params: \", test_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created best SVM, now optimize precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at ordinary confusion matrix. \n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = svm.predict(X_test)\n",
    "confusion = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "588 /(588+559)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now try lowering the threshold. \n",
    "y_pred_lower_threshold = svm.decision_function(X_test) >thresholds[close_zero]\n",
    "confusion = confusion_matrix(y_test,y_pred_lower_threshold)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds[close_zero]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now time for the precision recall curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision,recall,thresholds = precision_recall_curve(y_test,svm.decision_function(X_test))\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(precision[close_zero],recall[close_zero],'o')\n",
    "plt.plot(precision,recall,label = 'precision recall curve')\n",
    "plt.xlabel(\"precision\")\n",
    "plt.ylabel('recall')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.ind[max(precision)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([])\n",
    "\n",
    "data['Precision'] = precision\n",
    "data['recall'] = recall\n",
    "data['threshold'] = thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test,y_pred_higher_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision,recall, thresholds = precision_recall_curve(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_higher_threshold = svm.decision_function(X_test) >-.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred_lower_threshold)/len(y_pred_lower_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_trainval,X_test,y_trainval,y_test = train_test_split(X,y,random_state = 0)\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_trainval,y_trainval,random_state = 1)\n",
    "#print size of datasets here\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for alpha in [.0001,.001,.01]:\n",
    "    model = MLPClassifier(alpha=alpha)\n",
    "    model.fit(X_train,y_train)\n",
    "    score = model.score(X_val,y_val)\n",
    "    if score > best_score:\n",
    "        print(\"obtained score:\", score)\n",
    "\n",
    "        best_score = score\n",
    "        best_parameters = {'alpha' : alpha}\n",
    "\n",
    "model = MLPClassifier(alpha=best_parameters['alpha'])\n",
    "model.fit(X_trainval,y_trainval)\n",
    "test_score = model.score(X_test,y_test)\n",
    "print(\"best params: \",best_parameters['alpha'])\n",
    "print(\"test score w/ best params: \", test_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
