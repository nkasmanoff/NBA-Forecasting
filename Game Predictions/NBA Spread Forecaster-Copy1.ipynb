{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILENAME = 'NBADATA.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_rolling_dataset(window,FILENAME,spread=False,winner=False):\n",
    "    \"\"\"Uses the dataframe to create rolling averages, in \n",
    "        an attempt to capture a team's performance over an N game window prior to the game. \n",
    "    \"\"\"\n",
    "    \n",
    "    #retain relevant columns. \n",
    "    data = pd.read_csv(FILENAME) \n",
    "    data['3P%'] = np.divide(data['3P'].values,data['3PA'].values) \n",
    "    del data['3P'],data['3PA']\n",
    "    data['FG%'] = np.divide(data['FG'].values,data['FGA'].values)\n",
    "    del data['FG'],data['FGA']\n",
    "    data['FT%'] = np.divide(data['FT'].values,data['FTA'].values)\n",
    "    del data['Unnamed: 0'],data['PLUS_MINUS'],data['TOTAL']\n",
    "    del data['FT'],data['FTA']\n",
    "    del data['OU']\n",
    "#del data['Team']\n",
    "#data = pd.get_dummies(data)\n",
    "    teams = data.Team.unique()\n",
    "#iterate over those teams, make a rolling window over n games. \n",
    "    N_GAMES = window\n",
    "    nba_data = pd.DataFrame([])\n",
    "    season_ids = []\n",
    "    for i,val in enumerate(data['GAME_ID'].values):\n",
    "        season_ids.append(str(val)[1:3])\n",
    "\n",
    "    data['Season_ID'] = season_ids\n",
    "\n",
    "    for team in teams:\n",
    "       # print(team)\n",
    "    #get separate seasons here\n",
    "        team_data = data.loc[data['Team'] == team]  #this contains the box score of every team game from 2013 to 2018.\n",
    "        for season in data['Season_ID'].unique():\n",
    "            #print(season)\n",
    "            team_season = team_data.loc[team_data['Season_ID'] == season]\n",
    "        \n",
    "            stuff_to_turn_into_avgs = ['OR', 'DR', 'TOT', 'PF', 'ST', 'TO', 'BL', '3P%', 'FG%', 'FT%','PTS']\n",
    "            for col in team_season.columns:\n",
    "                if col in stuff_to_turn_into_avgs:\n",
    "            #split each season up here, \n",
    "                    team_season['Rolling ' + col] = team_season[col].rolling(window=N_GAMES).mean().shift(1)\n",
    "                    if col != 'PTS':\n",
    "                        del team_season[col]\n",
    "            nba_data =  nba_data.append(team_season)\n",
    "\n",
    "           # df = pd.concat([road_df,home_df],axis=1)\n",
    "#reorganize the dataset. \n",
    "    nba_data_splits = nba_data.sort_values(by = ['GAME_ID', 'Home'], ascending=[True, True])\n",
    "    nba_data_splits.dropna(inplace=True)  #null values come with rolling means, drop those now. \n",
    "\n",
    "#delete columns no longer of use, ie team name etc. Can consider keeping team name and see if helps chances. \n",
    "    del nba_data_splits['GAME_ID'],nba_data_splits['Home'],nba_data_splits['Away'],nba_data_splits['Date']\n",
    "    del nba_data_splits['Team']\n",
    "#now align the box scores so its one big one for each game, home team and road teams. \n",
    "\n",
    "    road_df = nba_data_splits.iloc[::2]\n",
    "    home_df = nba_data_splits.iloc[1::2]\n",
    "    for col in nba_data_splits.columns:\n",
    "        road_df['road_' + col] = road_df[col]\n",
    "        home_df['home_' + col] = home_df[col]\n",
    "    \n",
    "        del road_df[col],home_df[col]\n",
    "\n",
    "    home_df.reset_index(inplace=True)\n",
    "    road_df.reset_index(inplace=True)\n",
    "\n",
    "#merged into a dataframe here. \n",
    "    df = pd.concat([road_df,home_df],axis=1)\n",
    "    del df['index']\n",
    "\n",
    "#create the dataset here. Can consider the spread, or winner. \n",
    "#at the moment only using a single classifier, that seems sufficient. A home team loss is synonymous with a road team win. \n",
    "\n",
    "    df['final_SPREAD'] = df['road_PTS'] - df['home_PTS']\n",
    "    del df['road_PTS'], df['home_PTS'],df['home_SPREAD']\n",
    "           # if openspread + endspread <0:\n",
    "            #    y.append(np.array([0,1,0]))  #home team covered\n",
    "            #elif openspread + endspread >0:\n",
    "            #    y.append(np.array([1,0,0]))  #road covered\n",
    "           # else: \n",
    "           #     y.append(np.array([0,0,1]))  #push!\n",
    "    y = []\n",
    "\n",
    "    if spread: \n",
    "        for i in range(len(df)):\n",
    "            if df['road_SPREAD'].values[i] + df['final_SPREAD'].values[i] < 0:\n",
    "                y.append(1) #home team covers\n",
    "            else: # df['road_SPREAD'].values[i] + df['final_SPREAD'].values[i] > 0:\n",
    "                y.append(0) #road team covers or push\n",
    "    #else:\n",
    "    #    y.append(np.array([0,1]))  #push! \n",
    "    \n",
    "    if winner:\n",
    "        for i in range(len(df)):\n",
    "            if df['final_SPREAD'].values[i] < 0: #home team won. \n",
    "                y.append([0,1])\n",
    "            else:\n",
    "                y.append([1,0]) #road team won. \n",
    "\n",
    "    del df['final_SPREAD']\n",
    "\n",
    "#y_names = np.array(['road team win', 'home team win']) #for preprocessing/visualization. \n",
    "    X = df\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8e470c2be3eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_rolling_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFILENAME\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NBADATA.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-954e70f96cb2>\u001b[0m in \u001b[0;36mcreate_rolling_dataset\u001b[0;34m(window, FILENAME, spread, winner)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstuff_to_turn_into_avgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m#split each season up here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                     \u001b[0mteam_season\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Rolling '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteam_season\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_GAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'PTS'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                         \u001b[0;32mdel\u001b[0m \u001b[0mteam_season\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3199\u001b[0m         \u001b[0;31m# value exception to occur first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3201\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[0;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;31m# the copy weakref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2670\u001b[0;31m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2671\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_referents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2672\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X , y = create_rolling_dataset(window=5,FILENAME='NBADATA.csv',spread=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int(np.linspace(1,9,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "lookback = np.linspace(1,9,9)\n",
    "for window in lookback:\n",
    "    print(\"Testing \",window,\" day window size.\")\n",
    "    X , y = create_rolling_dataset(window=int(window),FILENAME='NBADATA.csv',spread=True)\n",
    "    X = X.values\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 0)\n",
    "\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    param_grid = {'C': [.127,.13,.133],'gamma': [.009,.01,.011]}\n",
    "\n",
    "    grid_search = GridSearchCV(SVC(),param_grid,cv=5)\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 0)\n",
    "\n",
    "    grid_search.fit(X_train,y_train)\n",
    "\n",
    "    test_score = grid_search.score(X_test,y_test)\n",
    "    print(\"Test set score: \", test_score)\n",
    "\n",
    "    cutoff  = 0.52381\n",
    "\n",
    "    if test_score>cutoff:\n",
    "        print(\"This is profitable!\")\n",
    "        winnings = 1*test_score - 1.1*(1-test_score)\n",
    "        print(\"in 10 games w/ 10$ bets, you'd make \", 100*winnings, 'with no outside input')\n",
    "        #print(grid_search.bestp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best windows. 8, 7, 4. These all profit over 1%, so further grid searching on these could lead to best outcome. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Day lookback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window1 = 4\n",
    "\n",
    "X , y = create_rolling_dataset(window=4,FILENAME='NBADATA.csv',spread=True)\n",
    "X = X.values\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train,X_test,y_train,y_test = train_test_split(X4,y4,random_state = 0)\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': np.linspace(.1,.15,10), 'gamma': [.007,.008,.0085]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(),param_grid,cv=5)\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "test_score = grid_search.score(X_test,y_test)\n",
    "print(\"Test set score: \", test_score)\n",
    "\n",
    "cutoff  = 0.52381\n",
    "\n",
    "if test_score>cutoff:\n",
    "    print(\"This is profitable!\")\n",
    "    winnings = 1*test_score - 1.1*(1-test_score)\n",
    "    print(\"in 10 games w/ 10$ bets, you'd make \", 100*winnings, 'with no outside interference')\n",
    "    print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window2 = 7\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Day lookback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "window3 = 8\n",
    "\n",
    "X , y = create_rolling_dataset(window=5,FILENAME='NBADATA.csv',spread=True)\n",
    "X = X.values\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 0)\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [.127,.13,.133],'gamma': [.009,.01,.011]}\n",
    "grid_search = GridSearchCV(SVC(),param_grid,cv=5)\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "test_score = grid_search.score(X_test,y_test)\n",
    "print(\"Test set score: \", test_score)\n",
    "\n",
    "cutoff  = 0.52381\n",
    "\n",
    "if test_score>cutoff:\n",
    "    print(\"This is profitable!\")\n",
    "    winnings = 1*test_score - 1.1*(1-test_score)\n",
    "    print(\"in 10 games w/ 10$ bets, you'd make \", 100*winnings, 'with no outside interference')\n",
    "    print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a different classifier here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 0)\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "param_grid={'learning_rate': [.001]}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(MLPClassifier(),param_grid,cv=5)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 0)\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "test_score = grid_search.score(X_test,y_test)\n",
    "print(\"Test set score: \", test_score)\n",
    "\n",
    "cutoff  = 0.52381\n",
    "\n",
    "if test_score>cutoff:\n",
    "    print(\"This is profitable!\")\n",
    "    winnings = 1*test_score - 1.1*(1-test_score)\n",
    "    print(\"in 10 games w/ 10$ bets, you'd make \", 100*winnings, 'with no outside input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
